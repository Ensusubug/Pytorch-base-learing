{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eac7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a465e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./日月光华-Pytorch/P4-二分类-多层感知器/HR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86811181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>part</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.11             0.88               7   \n",
       "3                    0.72             0.87               5   \n",
       "4                    0.37             0.52               2   \n",
       "...                   ...              ...             ...   \n",
       "14994                0.40             0.57               2   \n",
       "14995                0.37             0.48               2   \n",
       "14996                0.37             0.53               2   \n",
       "14997                0.11             0.96               6   \n",
       "14998                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       272                   4              0     1   \n",
       "3                       223                   5              0     1   \n",
       "4                       159                   3              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14994                   151                   3              0     1   \n",
       "14995                   160                   3              0     1   \n",
       "14996                   143                   3              0     1   \n",
       "14997                   280                   4              0     1   \n",
       "14998                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years     part  salary  \n",
       "0                          0    sales     low  \n",
       "1                          0    sales  medium  \n",
       "2                          0    sales  medium  \n",
       "3                          0    sales     low  \n",
       "4                          0    sales     low  \n",
       "...                      ...      ...     ...  \n",
       "14994                      0  support     low  \n",
       "14995                      0  support     low  \n",
       "14996                      0  support     low  \n",
       "14997                      0  support     low  \n",
       "14998                      0  support     low  \n",
       "\n",
       "[14999 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013b873d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sales', 'accounting', 'hr', 'technical', 'support', 'management',\n",
       "       'IT', 'product_mng', 'marketing', 'RandD'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.part.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f627f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low', 'medium', 'high'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.salary.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5588f3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary  part       \n",
       "high    IT               83\n",
       "        RandD            51\n",
       "        accounting       74\n",
       "        hr               45\n",
       "        management      225\n",
       "        marketing        80\n",
       "        product_mng      68\n",
       "        sales           269\n",
       "        support         141\n",
       "        technical       201\n",
       "low     IT              609\n",
       "        RandD           364\n",
       "        accounting      358\n",
       "        hr              335\n",
       "        management      180\n",
       "        marketing       402\n",
       "        product_mng     451\n",
       "        sales          2099\n",
       "        support        1146\n",
       "        technical      1372\n",
       "medium  IT              535\n",
       "        RandD           372\n",
       "        accounting      335\n",
       "        hr              359\n",
       "        management      225\n",
       "        marketing       376\n",
       "        product_mng     383\n",
       "        sales          1772\n",
       "        support         942\n",
       "        technical      1147\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['salary', 'part']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ef8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df919d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['salary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a4b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data.part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8366f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['part']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1226c5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>...</th>\n",
       "      <th>IT</th>\n",
       "      <th>RandD</th>\n",
       "      <th>accounting</th>\n",
       "      <th>hr</th>\n",
       "      <th>management</th>\n",
       "      <th>marketing</th>\n",
       "      <th>product_mng</th>\n",
       "      <th>sales</th>\n",
       "      <th>support</th>\n",
       "      <th>technical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.11             0.88               7   \n",
       "3                    0.72             0.87               5   \n",
       "4                    0.37             0.52               2   \n",
       "...                   ...              ...             ...   \n",
       "14994                0.40             0.57               2   \n",
       "14995                0.37             0.48               2   \n",
       "14996                0.37             0.53               2   \n",
       "14997                0.11             0.96               6   \n",
       "14998                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       272                   4              0     1   \n",
       "3                       223                   5              0     1   \n",
       "4                       159                   3              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14994                   151                   3              0     1   \n",
       "14995                   160                   3              0     1   \n",
       "14996                   143                   3              0     1   \n",
       "14997                   280                   4              0     1   \n",
       "14998                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years  high  low  ...  IT  RandD  accounting  hr  \\\n",
       "0                          0     0    1  ...   0      0           0   0   \n",
       "1                          0     0    0  ...   0      0           0   0   \n",
       "2                          0     0    0  ...   0      0           0   0   \n",
       "3                          0     0    1  ...   0      0           0   0   \n",
       "4                          0     0    1  ...   0      0           0   0   \n",
       "...                      ...   ...  ...  ...  ..    ...         ...  ..   \n",
       "14994                      0     0    1  ...   0      0           0   0   \n",
       "14995                      0     0    1  ...   0      0           0   0   \n",
       "14996                      0     0    1  ...   0      0           0   0   \n",
       "14997                      0     0    1  ...   0      0           0   0   \n",
       "14998                      0     0    1  ...   0      0           0   0   \n",
       "\n",
       "       management  marketing  product_mng  sales  support  technical  \n",
       "0               0          0            0      1        0          0  \n",
       "1               0          0            0      1        0          0  \n",
       "2               0          0            0      1        0          0  \n",
       "3               0          0            0      1        0          0  \n",
       "4               0          0            0      1        0          0  \n",
       "...           ...        ...          ...    ...      ...        ...  \n",
       "14994           0          0            0      0        1          0  \n",
       "14995           0          0            0      0        1          0  \n",
       "14996           0          0            0      0        1          0  \n",
       "14997           0          0            0      0        1          0  \n",
       "14998           0          0            0      0        1          0  \n",
       "\n",
       "[14999 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31aaa270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3571\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.left.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ecb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = data.left.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b478b1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdfcf1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.from_numpy(Y_data).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b0297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data[[c for c in data.columns if c != 'left']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0da4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_data.values).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "510b2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91fb613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1b0a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.liner_1 = nn.Linear(20, 64)\n",
    "        self.liner_2 = nn.Linear(64, 64)\n",
    "        self.liner_3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.liner_1(input))\n",
    "        x = F.relu(self.liner_2(x))\n",
    "        x = F.sigmoid(self.liner_3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba8c1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e349b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Model()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe5774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b76c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05198169",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "no_of_batches = len(data) // batch\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14d88893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.703342854976654\n",
      "epoch: 1 loss: 0.730451226234436\n",
      "epoch: 2 loss: 0.7295297384262085\n",
      "epoch: 3 loss: 0.7471882104873657\n",
      "epoch: 4 loss: 0.7200442552566528\n",
      "epoch: 5 loss: 0.714459240436554\n",
      "epoch: 6 loss: 0.7076644897460938\n",
      "epoch: 7 loss: 0.7006359696388245\n",
      "epoch: 8 loss: 0.6930137276649475\n",
      "epoch: 9 loss: 0.6853493452072144\n",
      "epoch: 10 loss: 0.6734954714775085\n",
      "epoch: 11 loss: 0.6592369675636292\n",
      "epoch: 12 loss: 0.6455115079879761\n",
      "epoch: 13 loss: 0.6367050409317017\n",
      "epoch: 14 loss: 0.6225218772888184\n",
      "epoch: 15 loss: 0.6152503490447998\n",
      "epoch: 16 loss: 0.6093650460243225\n",
      "epoch: 17 loss: 0.5997519493103027\n",
      "epoch: 18 loss: 0.5934404134750366\n",
      "epoch: 19 loss: 0.5875405073165894\n",
      "epoch: 20 loss: 0.5820364356040955\n",
      "epoch: 21 loss: 0.5775469541549683\n",
      "epoch: 22 loss: 0.572613000869751\n",
      "epoch: 23 loss: 0.5687732696533203\n",
      "epoch: 24 loss: 0.5661511421203613\n",
      "epoch: 25 loss: 0.5737399458885193\n",
      "epoch: 26 loss: 0.5654022097587585\n",
      "epoch: 27 loss: 0.5618929266929626\n",
      "epoch: 28 loss: 0.5586530566215515\n",
      "epoch: 29 loss: 0.555767297744751\n",
      "epoch: 30 loss: 0.5529086589813232\n",
      "epoch: 31 loss: 0.5528273582458496\n",
      "epoch: 32 loss: 0.5520996451377869\n",
      "epoch: 33 loss: 0.5513186454772949\n",
      "epoch: 34 loss: 0.5509777069091797\n",
      "epoch: 35 loss: 0.5508447289466858\n",
      "epoch: 36 loss: 0.5529723763465881\n",
      "epoch: 37 loss: 0.5507327914237976\n",
      "epoch: 38 loss: 0.5512604713439941\n",
      "epoch: 39 loss: 0.5512367486953735\n",
      "epoch: 40 loss: 0.5514652132987976\n",
      "epoch: 41 loss: 0.5516916513442993\n",
      "epoch: 42 loss: 0.5508066415786743\n",
      "epoch: 43 loss: 0.5521316528320312\n",
      "epoch: 44 loss: 0.5508245825767517\n",
      "epoch: 45 loss: 0.557785153388977\n",
      "epoch: 46 loss: 0.5494639873504639\n",
      "epoch: 47 loss: 0.5509870648384094\n",
      "epoch: 48 loss: 0.5523521304130554\n",
      "epoch: 49 loss: 0.5530757904052734\n",
      "epoch: 50 loss: 0.5529558658599854\n",
      "epoch: 51 loss: 0.5478578209877014\n",
      "epoch: 52 loss: 0.5519108772277832\n",
      "epoch: 53 loss: 0.5519740581512451\n",
      "epoch: 54 loss: 0.5471879839897156\n",
      "epoch: 55 loss: 0.551205039024353\n",
      "epoch: 56 loss: 0.5650264620780945\n",
      "epoch: 57 loss: 0.5519493222236633\n",
      "epoch: 58 loss: 0.5511882901191711\n",
      "epoch: 59 loss: 0.5484861135482788\n",
      "epoch: 60 loss: 0.5475579500198364\n",
      "epoch: 61 loss: 0.5504952669143677\n",
      "epoch: 62 loss: 0.5485737323760986\n",
      "epoch: 63 loss: 0.545776903629303\n",
      "epoch: 64 loss: 0.5487552285194397\n",
      "epoch: 65 loss: 0.5486109256744385\n",
      "epoch: 66 loss: 0.5468882918357849\n",
      "epoch: 67 loss: 0.5479591488838196\n",
      "epoch: 68 loss: 0.543580174446106\n",
      "epoch: 69 loss: 0.5474662780761719\n",
      "epoch: 70 loss: 0.5446367263793945\n",
      "epoch: 71 loss: 0.5446771383285522\n",
      "epoch: 72 loss: 0.5446975231170654\n",
      "epoch: 73 loss: 0.540644645690918\n",
      "epoch: 74 loss: 0.5503767728805542\n",
      "epoch: 75 loss: 0.5442825555801392\n",
      "epoch: 76 loss: 0.5445857644081116\n",
      "epoch: 77 loss: 0.5358523726463318\n",
      "epoch: 78 loss: 0.5403492450714111\n",
      "epoch: 79 loss: 0.5350935459136963\n",
      "epoch: 80 loss: 0.5356201529502869\n",
      "epoch: 81 loss: 0.5343045592308044\n",
      "epoch: 82 loss: 0.5343666672706604\n",
      "epoch: 83 loss: 0.5312979221343994\n",
      "epoch: 84 loss: 0.5288950204849243\n",
      "epoch: 85 loss: 0.5310880541801453\n",
      "epoch: 86 loss: 0.5295506715774536\n",
      "epoch: 87 loss: 0.5286814570426941\n",
      "epoch: 88 loss: 0.5278604030609131\n",
      "epoch: 89 loss: 0.5300267934799194\n",
      "epoch: 90 loss: 0.5704025626182556\n",
      "epoch: 91 loss: 0.5279725193977356\n",
      "epoch: 92 loss: 0.5553825497627258\n",
      "epoch: 93 loss: 0.5263490676879883\n",
      "epoch: 94 loss: 0.5260043144226074\n",
      "epoch: 95 loss: 0.5201146602630615\n",
      "epoch: 96 loss: 0.5190900564193726\n",
      "epoch: 97 loss: 0.5158509016036987\n",
      "epoch: 98 loss: 0.5140195488929749\n",
      "epoch: 99 loss: 0.5138785243034363\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        start = i * batch\n",
    "        end = start + batch\n",
    "        x = X[start:end]\n",
    "        y = Y[start:end]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:',epoch, 'loss:',loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1f78c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5139, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0f3580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e6fd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HRdataset = TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "082d6899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.3800,   0.5300,   2.0000, 157.0000,   3.0000,   0.0000,   0.0000,\n",
       "           0.0000,   1.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   0.0000]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HRdataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07b02e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "decd63d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.7286790609359741\n",
      "epoch: 1 loss: 0.7460217475891113\n",
      "epoch: 2 loss: 0.7516049742698669\n",
      "epoch: 3 loss: 0.763351321220398\n",
      "epoch: 4 loss: 0.753433883190155\n",
      "epoch: 5 loss: 0.7489601373672485\n",
      "epoch: 6 loss: 0.7440798282623291\n",
      "epoch: 7 loss: 0.7388703227043152\n",
      "epoch: 8 loss: 0.7211987376213074\n",
      "epoch: 9 loss: 0.7147953510284424\n",
      "epoch: 10 loss: 0.7036678194999695\n",
      "epoch: 11 loss: 0.6879817247390747\n",
      "epoch: 12 loss: 0.6799395084381104\n",
      "epoch: 13 loss: 0.690778911113739\n",
      "epoch: 14 loss: 0.6661193370819092\n",
      "epoch: 15 loss: 0.6563441753387451\n",
      "epoch: 16 loss: 0.6439422965049744\n",
      "epoch: 17 loss: 0.6251721382141113\n",
      "epoch: 18 loss: 0.6199224591255188\n",
      "epoch: 19 loss: 0.6123490333557129\n",
      "epoch: 20 loss: 0.6067693829536438\n",
      "epoch: 21 loss: 0.598041832447052\n",
      "epoch: 22 loss: 0.5931865572929382\n",
      "epoch: 23 loss: 0.5864433646202087\n",
      "epoch: 24 loss: 0.5856627821922302\n",
      "epoch: 25 loss: 0.5755500197410583\n",
      "epoch: 26 loss: 0.57421875\n",
      "epoch: 27 loss: 0.5821845531463623\n",
      "epoch: 28 loss: 0.5715405941009521\n",
      "epoch: 29 loss: 0.5667369365692139\n",
      "epoch: 30 loss: 0.5630149245262146\n",
      "epoch: 31 loss: 0.56019526720047\n",
      "epoch: 32 loss: 0.5578000545501709\n",
      "epoch: 33 loss: 0.5543329119682312\n",
      "epoch: 34 loss: 0.5587882995605469\n",
      "epoch: 35 loss: 0.5587517619132996\n",
      "epoch: 36 loss: 0.5550456047058105\n",
      "epoch: 37 loss: 0.5526038408279419\n",
      "epoch: 38 loss: 0.5528152585029602\n",
      "epoch: 39 loss: 0.5516581535339355\n",
      "epoch: 40 loss: 0.5509874224662781\n",
      "epoch: 41 loss: 0.5505258440971375\n",
      "epoch: 42 loss: 0.5537843108177185\n",
      "epoch: 43 loss: 0.5519148111343384\n",
      "epoch: 44 loss: 0.5518655180931091\n",
      "epoch: 45 loss: 0.5501199960708618\n",
      "epoch: 46 loss: 0.5522753596305847\n",
      "epoch: 47 loss: 0.5498195886611938\n",
      "epoch: 48 loss: 0.551095187664032\n",
      "epoch: 49 loss: 0.5496381521224976\n",
      "epoch: 50 loss: 0.5505715608596802\n",
      "epoch: 51 loss: 0.5492071509361267\n",
      "epoch: 52 loss: 0.5552624464035034\n",
      "epoch: 53 loss: 0.5472083687782288\n",
      "epoch: 54 loss: 0.5503182411193848\n",
      "epoch: 55 loss: 0.5495315790176392\n",
      "epoch: 56 loss: 0.5477139949798584\n",
      "epoch: 57 loss: 0.5434173941612244\n",
      "epoch: 58 loss: 0.5546886920928955\n",
      "epoch: 59 loss: 0.5444638729095459\n",
      "epoch: 60 loss: 0.5459145903587341\n",
      "epoch: 61 loss: 0.5418609380722046\n",
      "epoch: 62 loss: 0.5440083146095276\n",
      "epoch: 63 loss: 0.5459632277488708\n",
      "epoch: 64 loss: 0.5418298840522766\n",
      "epoch: 65 loss: 0.5409753918647766\n",
      "epoch: 66 loss: 0.5446189641952515\n",
      "epoch: 67 loss: 0.5465554594993591\n",
      "epoch: 68 loss: 0.541954755783081\n",
      "epoch: 69 loss: 0.5382778644561768\n",
      "epoch: 70 loss: 0.5372545123100281\n",
      "epoch: 71 loss: 0.540378987789154\n",
      "epoch: 72 loss: 0.5349081754684448\n",
      "epoch: 73 loss: 0.5378564596176147\n",
      "epoch: 74 loss: 0.5358110666275024\n",
      "epoch: 75 loss: 0.5337294340133667\n",
      "epoch: 76 loss: 0.5340553522109985\n",
      "epoch: 77 loss: 0.5358584523200989\n",
      "epoch: 78 loss: 0.5329268574714661\n",
      "epoch: 79 loss: 0.5356220602989197\n",
      "epoch: 80 loss: 0.5321284532546997\n",
      "epoch: 81 loss: 0.5341999530792236\n",
      "epoch: 82 loss: 0.5306487679481506\n",
      "epoch: 83 loss: 0.5328105688095093\n",
      "epoch: 84 loss: 0.5282802581787109\n",
      "epoch: 85 loss: 0.5439893007278442\n",
      "epoch: 86 loss: 0.5288911461830139\n",
      "epoch: 87 loss: 0.5256235599517822\n",
      "epoch: 88 loss: 0.5259531140327454\n",
      "epoch: 89 loss: 0.5268975496292114\n",
      "epoch: 90 loss: 0.5246016979217529\n",
      "epoch: 91 loss: 0.5243566632270813\n",
      "epoch: 92 loss: 0.5223026871681213\n",
      "epoch: 93 loss: 0.5198408365249634\n",
      "epoch: 94 loss: 0.5207366943359375\n",
      "epoch: 95 loss: 0.5177385807037354\n",
      "epoch: 96 loss: 0.5190567374229431\n",
      "epoch: 97 loss: 0.5158789753913879\n",
      "epoch: 98 loss: 0.5180385708808899\n",
      "epoch: 99 loss: 0.5149197578430176\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(no_of_batches):\n",
    "        x, y = HRdataset[i*batch : i*batch+batch]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:',epoch, 'loss:',loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96aed6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "377aca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_ds = TensorDataset(X, Y)\n",
    "hr_dl = DataLoader(hr_ds, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7c42a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "666dca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.5643060207366943\n",
      "epoch: 1 loss: 0.5604581832885742\n",
      "epoch: 2 loss: 0.5581472516059875\n",
      "epoch: 3 loss: 0.5561212301254272\n",
      "epoch: 4 loss: 0.5542844533920288\n",
      "epoch: 5 loss: 0.547860324382782\n",
      "epoch: 6 loss: 0.5438026189804077\n",
      "epoch: 7 loss: 0.5399348735809326\n",
      "epoch: 8 loss: 0.5328302979469299\n",
      "epoch: 9 loss: 0.5229706764221191\n",
      "epoch: 10 loss: 0.5142322778701782\n",
      "epoch: 11 loss: 0.5047183632850647\n",
      "epoch: 12 loss: 0.4942739009857178\n",
      "epoch: 13 loss: 0.4878416657447815\n",
      "epoch: 14 loss: 0.47787755727767944\n",
      "epoch: 15 loss: 0.4597723186016083\n",
      "epoch: 16 loss: 0.4492787718772888\n",
      "epoch: 17 loss: 0.43939200043678284\n",
      "epoch: 18 loss: 0.4366733431816101\n",
      "epoch: 19 loss: 0.4184196889400482\n",
      "epoch: 20 loss: 0.40686696767807007\n",
      "epoch: 21 loss: 0.3971773684024811\n",
      "epoch: 22 loss: 0.3925917148590088\n",
      "epoch: 23 loss: 0.37996959686279297\n",
      "epoch: 24 loss: 0.3770425319671631\n",
      "epoch: 25 loss: 0.36388278007507324\n",
      "epoch: 26 loss: 0.3637028634548187\n",
      "epoch: 27 loss: 0.3487946093082428\n",
      "epoch: 28 loss: 0.34984323382377625\n",
      "epoch: 29 loss: 0.33696919679641724\n",
      "epoch: 30 loss: 0.3331870436668396\n",
      "epoch: 31 loss: 0.3261052966117859\n",
      "epoch: 32 loss: 0.3220065236091614\n",
      "epoch: 33 loss: 0.31963545083999634\n",
      "epoch: 34 loss: 0.31032854318618774\n",
      "epoch: 35 loss: 0.3093653917312622\n",
      "epoch: 36 loss: 0.30335646867752075\n",
      "epoch: 37 loss: 0.2985568642616272\n",
      "epoch: 38 loss: 0.29686063528060913\n",
      "epoch: 39 loss: 0.2904933989048004\n",
      "epoch: 40 loss: 0.28713464736938477\n",
      "epoch: 41 loss: 0.2884325385093689\n",
      "epoch: 42 loss: 0.2819894552230835\n",
      "epoch: 43 loss: 0.2865707576274872\n",
      "epoch: 44 loss: 0.28314581513404846\n",
      "epoch: 45 loss: 0.2742292582988739\n",
      "epoch: 46 loss: 0.27247223258018494\n",
      "epoch: 47 loss: 0.2701396048069\n",
      "epoch: 48 loss: 0.2694430947303772\n",
      "epoch: 49 loss: 0.26744160056114197\n",
      "epoch: 50 loss: 0.2674635052680969\n",
      "epoch: 51 loss: 0.2634390592575073\n",
      "epoch: 52 loss: 0.26897138357162476\n",
      "epoch: 53 loss: 0.2777624726295471\n",
      "epoch: 54 loss: 0.2651558816432953\n",
      "epoch: 55 loss: 0.2587161660194397\n",
      "epoch: 56 loss: 0.2599223554134369\n",
      "epoch: 57 loss: 0.2626782953739166\n",
      "epoch: 58 loss: 0.2589150071144104\n",
      "epoch: 59 loss: 0.2593109905719757\n",
      "epoch: 60 loss: 0.2541781961917877\n",
      "epoch: 61 loss: 0.2532092034816742\n",
      "epoch: 62 loss: 0.2529163956642151\n",
      "epoch: 63 loss: 0.2506977915763855\n",
      "epoch: 64 loss: 0.2547488808631897\n",
      "epoch: 65 loss: 0.25260379910469055\n",
      "epoch: 66 loss: 0.26169395446777344\n",
      "epoch: 67 loss: 0.2537727653980255\n",
      "epoch: 68 loss: 0.24845418334007263\n",
      "epoch: 69 loss: 0.24682319164276123\n",
      "epoch: 70 loss: 0.258669912815094\n",
      "epoch: 71 loss: 0.25757667422294617\n",
      "epoch: 72 loss: 0.25625380873680115\n",
      "epoch: 73 loss: 0.2449205368757248\n",
      "epoch: 74 loss: 0.24682500958442688\n",
      "epoch: 75 loss: 0.26286551356315613\n",
      "epoch: 76 loss: 0.2432185560464859\n",
      "epoch: 77 loss: 0.24161043763160706\n",
      "epoch: 78 loss: 0.24390457570552826\n",
      "epoch: 79 loss: 0.24439914524555206\n",
      "epoch: 80 loss: 0.24862666428089142\n",
      "epoch: 81 loss: 0.2399306744337082\n",
      "epoch: 82 loss: 0.2403116077184677\n",
      "epoch: 83 loss: 0.23795969784259796\n",
      "epoch: 84 loss: 0.24036051332950592\n",
      "epoch: 85 loss: 0.23930387198925018\n",
      "epoch: 86 loss: 0.2379225641489029\n",
      "epoch: 87 loss: 0.23826836049556732\n",
      "epoch: 88 loss: 0.24376262724399567\n",
      "epoch: 89 loss: 0.23573827743530273\n",
      "epoch: 90 loss: 0.2340586930513382\n",
      "epoch: 91 loss: 0.23834526538848877\n",
      "epoch: 92 loss: 0.23537401854991913\n",
      "epoch: 93 loss: 0.23290815949440002\n",
      "epoch: 94 loss: 0.23331202566623688\n",
      "epoch: 95 loss: 0.2325582653284073\n",
      "epoch: 96 loss: 0.23718804121017456\n",
      "epoch: 97 loss: 0.2336517721414566\n",
      "epoch: 98 loss: 0.23155294358730316\n",
      "epoch: 99 loss: 0.23162615299224854\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in hr_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        print('epoch:',epoch, 'loss:',loss_fn(model(X), Y).data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f21276ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8506436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6956eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x.values).type(torch.float32)\n",
    "test_x = torch.from_numpy(test_x.values).type(torch.float32)\n",
    "train_y = torch.from_numpy(train_y).type(torch.float32)\n",
    "test_y = torch.from_numpy(test_y).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b20f2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(train_x, train_y)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39e662a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = TensorDataset(test_x, test_y)\n",
    "tese_dl = DataLoader(test_ds, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "300cdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = (y_pred > 0.5).type(torch.int32)\n",
    "    acc = (y_pred == y_true).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e30df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optim = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b395251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss: 0.234 train_accuracy: 0.917 test_loss: 0.238 test_accuracy: 0.912\n",
      "epoch: 1 train_loss: 0.239 train_accuracy: 0.914 test_loss: 0.244 test_accuracy: 0.907\n",
      "epoch: 2 train_loss: 0.246 train_accuracy: 0.911 test_loss: 0.252 test_accuracy: 0.906\n",
      "epoch: 3 train_loss: 0.241 train_accuracy: 0.908 test_loss: 0.244 test_accuracy: 0.904\n",
      "epoch: 4 train_loss: 0.238 train_accuracy: 0.911 test_loss: 0.241 test_accuracy: 0.906\n",
      "epoch: 5 train_loss: 0.233 train_accuracy: 0.917 test_loss: 0.238 test_accuracy: 0.911\n",
      "epoch: 6 train_loss: 0.242 train_accuracy: 0.907 test_loss: 0.246 test_accuracy: 0.902\n",
      "epoch: 7 train_loss: 0.234 train_accuracy: 0.915 test_loss: 0.238 test_accuracy: 0.91\n",
      "epoch: 8 train_loss: 0.244 train_accuracy: 0.913 test_loss: 0.25 test_accuracy: 0.907\n",
      "epoch: 9 train_loss: 0.233 train_accuracy: 0.917 test_loss: 0.238 test_accuracy: 0.911\n",
      "epoch: 10 train_loss: 0.238 train_accuracy: 0.91 test_loss: 0.241 test_accuracy: 0.908\n",
      "epoch: 11 train_loss: 0.238 train_accuracy: 0.91 test_loss: 0.242 test_accuracy: 0.905\n",
      "epoch: 12 train_loss: 0.233 train_accuracy: 0.917 test_loss: 0.237 test_accuracy: 0.911\n",
      "epoch: 13 train_loss: 0.234 train_accuracy: 0.915 test_loss: 0.239 test_accuracy: 0.909\n",
      "epoch: 14 train_loss: 0.232 train_accuracy: 0.917 test_loss: 0.236 test_accuracy: 0.912\n",
      "epoch: 15 train_loss: 0.241 train_accuracy: 0.911 test_loss: 0.245 test_accuracy: 0.907\n",
      "epoch: 16 train_loss: 0.232 train_accuracy: 0.917 test_loss: 0.236 test_accuracy: 0.912\n",
      "epoch: 17 train_loss: 0.234 train_accuracy: 0.913 test_loss: 0.238 test_accuracy: 0.91\n",
      "epoch: 18 train_loss: 0.236 train_accuracy: 0.912 test_loss: 0.24 test_accuracy: 0.91\n",
      "epoch: 19 train_loss: 0.24 train_accuracy: 0.909 test_loss: 0.243 test_accuracy: 0.901\n",
      "epoch: 20 train_loss: 0.238 train_accuracy: 0.91 test_loss: 0.241 test_accuracy: 0.906\n",
      "epoch: 21 train_loss: 0.246 train_accuracy: 0.909 test_loss: 0.252 test_accuracy: 0.904\n",
      "epoch: 22 train_loss: 0.232 train_accuracy: 0.917 test_loss: 0.237 test_accuracy: 0.912\n",
      "epoch: 23 train_loss: 0.263 train_accuracy: 0.895 test_loss: 0.271 test_accuracy: 0.89\n",
      "epoch: 24 train_loss: 0.233 train_accuracy: 0.913 test_loss: 0.237 test_accuracy: 0.911\n",
      "epoch: 25 train_loss: 0.232 train_accuracy: 0.915 test_loss: 0.235 test_accuracy: 0.913\n",
      "epoch: 26 train_loss: 0.238 train_accuracy: 0.915 test_loss: 0.244 test_accuracy: 0.909\n",
      "epoch: 27 train_loss: 0.23 train_accuracy: 0.918 test_loss: 0.234 test_accuracy: 0.913\n",
      "epoch: 28 train_loss: 0.231 train_accuracy: 0.916 test_loss: 0.235 test_accuracy: 0.914\n",
      "epoch: 29 train_loss: 0.23 train_accuracy: 0.918 test_loss: 0.234 test_accuracy: 0.914\n",
      "epoch: 30 train_loss: 0.236 train_accuracy: 0.916 test_loss: 0.241 test_accuracy: 0.91\n",
      "epoch: 31 train_loss: 0.231 train_accuracy: 0.915 test_loss: 0.235 test_accuracy: 0.912\n",
      "epoch: 32 train_loss: 0.229 train_accuracy: 0.918 test_loss: 0.233 test_accuracy: 0.914\n",
      "epoch: 33 train_loss: 0.232 train_accuracy: 0.916 test_loss: 0.237 test_accuracy: 0.914\n",
      "epoch: 34 train_loss: 0.237 train_accuracy: 0.914 test_loss: 0.243 test_accuracy: 0.909\n",
      "epoch: 35 train_loss: 0.232 train_accuracy: 0.912 test_loss: 0.236 test_accuracy: 0.909\n",
      "epoch: 36 train_loss: 0.23 train_accuracy: 0.918 test_loss: 0.235 test_accuracy: 0.913\n",
      "epoch: 37 train_loss: 0.23 train_accuracy: 0.915 test_loss: 0.234 test_accuracy: 0.912\n",
      "epoch: 38 train_loss: 0.237 train_accuracy: 0.91 test_loss: 0.24 test_accuracy: 0.904\n",
      "epoch: 39 train_loss: 0.229 train_accuracy: 0.919 test_loss: 0.234 test_accuracy: 0.913\n",
      "epoch: 40 train_loss: 0.23 train_accuracy: 0.916 test_loss: 0.234 test_accuracy: 0.913\n",
      "epoch: 41 train_loss: 0.229 train_accuracy: 0.918 test_loss: 0.234 test_accuracy: 0.915\n",
      "epoch: 42 train_loss: 0.229 train_accuracy: 0.918 test_loss: 0.235 test_accuracy: 0.913\n",
      "epoch: 43 train_loss: 0.236 train_accuracy: 0.914 test_loss: 0.242 test_accuracy: 0.908\n",
      "epoch: 44 train_loss: 0.231 train_accuracy: 0.916 test_loss: 0.235 test_accuracy: 0.912\n",
      "epoch: 45 train_loss: 0.229 train_accuracy: 0.914 test_loss: 0.233 test_accuracy: 0.913\n",
      "epoch: 46 train_loss: 0.236 train_accuracy: 0.91 test_loss: 0.24 test_accuracy: 0.904\n",
      "epoch: 47 train_loss: 0.241 train_accuracy: 0.907 test_loss: 0.244 test_accuracy: 0.906\n",
      "epoch: 48 train_loss: 0.231 train_accuracy: 0.917 test_loss: 0.235 test_accuracy: 0.912\n",
      "epoch: 49 train_loss: 0.233 train_accuracy: 0.915 test_loss: 0.239 test_accuracy: 0.911\n",
      "epoch: 50 train_loss: 0.236 train_accuracy: 0.91 test_loss: 0.239 test_accuracy: 0.902\n",
      "epoch: 51 train_loss: 0.226 train_accuracy: 0.918 test_loss: 0.231 test_accuracy: 0.914\n",
      "epoch: 52 train_loss: 0.226 train_accuracy: 0.919 test_loss: 0.23 test_accuracy: 0.915\n",
      "epoch: 53 train_loss: 0.229 train_accuracy: 0.915 test_loss: 0.233 test_accuracy: 0.912\n",
      "epoch: 54 train_loss: 0.228 train_accuracy: 0.918 test_loss: 0.234 test_accuracy: 0.914\n",
      "epoch: 55 train_loss: 0.225 train_accuracy: 0.92 test_loss: 0.23 test_accuracy: 0.915\n",
      "epoch: 56 train_loss: 0.231 train_accuracy: 0.917 test_loss: 0.237 test_accuracy: 0.912\n",
      "epoch: 57 train_loss: 0.232 train_accuracy: 0.912 test_loss: 0.236 test_accuracy: 0.91\n",
      "epoch: 58 train_loss: 0.225 train_accuracy: 0.917 test_loss: 0.229 test_accuracy: 0.914\n",
      "epoch: 59 train_loss: 0.224 train_accuracy: 0.919 test_loss: 0.229 test_accuracy: 0.914\n",
      "epoch: 60 train_loss: 0.225 train_accuracy: 0.918 test_loss: 0.232 test_accuracy: 0.914\n",
      "epoch: 61 train_loss: 0.225 train_accuracy: 0.919 test_loss: 0.231 test_accuracy: 0.915\n",
      "epoch: 62 train_loss: 0.225 train_accuracy: 0.921 test_loss: 0.231 test_accuracy: 0.916\n",
      "epoch: 63 train_loss: 0.225 train_accuracy: 0.918 test_loss: 0.229 test_accuracy: 0.915\n",
      "epoch: 64 train_loss: 0.222 train_accuracy: 0.921 test_loss: 0.228 test_accuracy: 0.916\n",
      "epoch: 65 train_loss: 0.226 train_accuracy: 0.915 test_loss: 0.231 test_accuracy: 0.912\n",
      "epoch: 66 train_loss: 0.23 train_accuracy: 0.912 test_loss: 0.234 test_accuracy: 0.905\n",
      "epoch: 67 train_loss: 0.228 train_accuracy: 0.915 test_loss: 0.232 test_accuracy: 0.909\n",
      "epoch: 68 train_loss: 0.236 train_accuracy: 0.908 test_loss: 0.239 test_accuracy: 0.9\n",
      "epoch: 69 train_loss: 0.222 train_accuracy: 0.92 test_loss: 0.227 test_accuracy: 0.916\n",
      "epoch: 70 train_loss: 0.223 train_accuracy: 0.921 test_loss: 0.228 test_accuracy: 0.919\n",
      "epoch: 71 train_loss: 0.224 train_accuracy: 0.919 test_loss: 0.229 test_accuracy: 0.915\n",
      "epoch: 72 train_loss: 0.229 train_accuracy: 0.914 test_loss: 0.233 test_accuracy: 0.908\n",
      "epoch: 73 train_loss: 0.221 train_accuracy: 0.923 test_loss: 0.227 test_accuracy: 0.917\n",
      "epoch: 74 train_loss: 0.24 train_accuracy: 0.907 test_loss: 0.244 test_accuracy: 0.899\n",
      "epoch: 75 train_loss: 0.229 train_accuracy: 0.921 test_loss: 0.235 test_accuracy: 0.916\n",
      "epoch: 76 train_loss: 0.222 train_accuracy: 0.919 test_loss: 0.227 test_accuracy: 0.915\n",
      "epoch: 77 train_loss: 0.226 train_accuracy: 0.914 test_loss: 0.231 test_accuracy: 0.91\n",
      "epoch: 78 train_loss: 0.219 train_accuracy: 0.922 test_loss: 0.225 test_accuracy: 0.919\n",
      "epoch: 79 train_loss: 0.22 train_accuracy: 0.923 test_loss: 0.226 test_accuracy: 0.918\n",
      "epoch: 80 train_loss: 0.226 train_accuracy: 0.918 test_loss: 0.231 test_accuracy: 0.914\n",
      "epoch: 81 train_loss: 0.22 train_accuracy: 0.922 test_loss: 0.226 test_accuracy: 0.919\n",
      "epoch: 82 train_loss: 0.22 train_accuracy: 0.921 test_loss: 0.226 test_accuracy: 0.916\n",
      "epoch: 83 train_loss: 0.222 train_accuracy: 0.922 test_loss: 0.229 test_accuracy: 0.919\n",
      "epoch: 84 train_loss: 0.221 train_accuracy: 0.924 test_loss: 0.228 test_accuracy: 0.919\n",
      "epoch: 85 train_loss: 0.22 train_accuracy: 0.923 test_loss: 0.227 test_accuracy: 0.92\n",
      "epoch: 86 train_loss: 0.221 train_accuracy: 0.921 test_loss: 0.227 test_accuracy: 0.919\n",
      "epoch: 87 train_loss: 0.22 train_accuracy: 0.921 test_loss: 0.226 test_accuracy: 0.917\n",
      "epoch: 88 train_loss: 0.242 train_accuracy: 0.915 test_loss: 0.251 test_accuracy: 0.909\n",
      "epoch: 89 train_loss: 0.217 train_accuracy: 0.925 test_loss: 0.223 test_accuracy: 0.921\n",
      "epoch: 90 train_loss: 0.218 train_accuracy: 0.924 test_loss: 0.225 test_accuracy: 0.918\n",
      "epoch: 91 train_loss: 0.22 train_accuracy: 0.92 test_loss: 0.226 test_accuracy: 0.918\n",
      "epoch: 92 train_loss: 0.221 train_accuracy: 0.922 test_loss: 0.228 test_accuracy: 0.917\n",
      "epoch: 93 train_loss: 0.228 train_accuracy: 0.918 test_loss: 0.238 test_accuracy: 0.913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94 train_loss: 0.22 train_accuracy: 0.923 test_loss: 0.228 test_accuracy: 0.919\n",
      "epoch: 95 train_loss: 0.23 train_accuracy: 0.911 test_loss: 0.234 test_accuracy: 0.905\n",
      "epoch: 96 train_loss: 0.228 train_accuracy: 0.913 test_loss: 0.233 test_accuracy: 0.907\n",
      "epoch: 97 train_loss: 0.223 train_accuracy: 0.915 test_loss: 0.229 test_accuracy: 0.911\n",
      "epoch: 98 train_loss: 0.219 train_accuracy: 0.92 test_loss: 0.225 test_accuracy: 0.916\n",
      "epoch: 99 train_loss: 0.219 train_accuracy: 0.921 test_loss: 0.225 test_accuracy: 0.917\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in train_dl:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    with torch.no_grad():\n",
    "        epoch_acc = accuracy(model(train_x), train_y)\n",
    "        epoch_loss = loss_fn(model(train_x), train_y).data.item()\n",
    "        \n",
    "        epoch_test_acc = accuracy(model(test_x), test_y)\n",
    "        epoch_test_loss = loss_fn(model(test_x), test_y).data.item()\n",
    "        print('epoch:',epoch, 'train_loss:',round(epoch_loss, 3),\n",
    "                              'train_accuracy:', round(epoch_acc.item(), 3),\n",
    "                              'test_loss:',round(epoch_test_loss, 3),\n",
    "                              'test_accuracy:', round(epoch_test_acc.item(), 3)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ceab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
